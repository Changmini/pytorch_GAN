{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "subject-pavilion",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.init as init\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  \n",
    "\n",
    "import random\n",
    "\n",
    "from torchvision import datasets\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import Image, display\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "touched-understanding",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "learning_rate = 0.0001\n",
    "num_epoch = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "official-transfer",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Data\n",
    "dataset_train = datasets.ImageFolder(root='/content/drive/My Drive/AI/input/data/train', transform=transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "dataset_test = datasets.ImageFolder(root='/content/drive/My Drive/AI/input/data/temp', transform=transforms.Compose([\n",
    "    transforms.Resize(64),\n",
    "    transforms.ToTensor(), \n",
    "]))\n",
    "train_dataloader = torch.utils.data.DataLoader(dataset_train, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = torch.utils.data.DataLoader(dataset_test, batch_size=batch_size, shuffle=True)\n",
    "len(dataset_train.imgs), len(train_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "endangered-guitar",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fixed input for debugging\n",
    "\n",
    "fixed_x, _ = next(iter(test_dataloader))\n",
    "save_image(fixed_x, 'real_image.png')\n",
    "\n",
    "Image('real_image.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "vocal-estate",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self,num_feature=32):\n",
    "        super(CNN,self).__init__()\n",
    "        self.num_feature = num_feature\n",
    "        \n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=self.num_feature, kernel_size=3,stride=1,padding=1),\n",
    "            nn.BatchNorm2d(self.num_feature),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(self.num_feature,self.num_feature*2,3,1,1), #64\n",
    "            nn.BatchNorm2d(self.num_feature*2),\n",
    "            nn.ReLU(),\n",
    "            nn.AvgPool2d(2,2),\n",
    "            \n",
    "            nn.Conv2d(self.num_feature*2,self.num_feature*4,3,1,1), #128\n",
    "            nn.BatchNorm2d(self.num_feature*4),\n",
    "            nn.ReLU(),\n",
    "\n",
    "            nn.Conv2d(self.num_feature*4,self.num_feature*8,3,1,1), #256\n",
    "            nn.BatchNorm2d(self.num_feature*8),\n",
    "            nn.AvgPool2d(2,2),\n",
    "            nn.ReLU(),\n",
    "            \n",
    "            nn.Conv2d(self.num_feature*8,self.num_feature*16,3,1,1), #512\n",
    "            nn.BatchNorm2d(self.num_feature*16),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(self.num_feature*4096,3000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(3000,1000),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1000,2)\n",
    "        )       \n",
    "        \n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Conv2d):\n",
    "                # Kaming Initialization\n",
    "                init.kaiming_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "            elif isinstance(m, nn.Linear):\n",
    "                # Kaming Initialization\n",
    "                init.kaiming_normal(m.weight.data)\n",
    "                m.bias.data.fill_(0)\n",
    "        \n",
    "        \n",
    "    def forward(self,x):\n",
    "        out = self.layer(x)\n",
    "        out = out.view(x.size()[0],-1)\n",
    "        out = self.fc_layer(out)\n",
    "        return out\n",
    "\n",
    "model = nn.DataParallel(CNN().cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "front-lawrence",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "statewide-diabetes",
   "metadata": {},
   "outputs": [],
   "source": [
    "check = []\n",
    "for i in range(num_epoch):\n",
    "    model.train()\n",
    "    for j,[image,label] in enumerate(train_dataloader):\n",
    "        img = Variable(image).cuda()\n",
    "        img = img.float ()\n",
    "        real_label= Variable(label).cuda()\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        output = model.forward(img)\n",
    "\n",
    "        loss = loss_func(output,real_label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "    succ_count = torch.FloatTensor([0])\n",
    "    total = torch.FloatTensor([0])\n",
    "    model.eval() \n",
    "    \n",
    "    for image,label in test_dataloader:\n",
    "        img = Variable(image,volatile=True).cuda()\n",
    "        img = img.float ()\n",
    "        real_label= Variable(label).cuda()\n",
    "\n",
    "        output = model.forward(img)\n",
    "        \n",
    "        _, predicted = output.max(dim=1)\n",
    "        # check data [Predicted_V, Original_V]\n",
    "        check = [\"Predicted_V : \",predicted, \"Original_V : \", real_label]\n",
    "\n",
    "        # 분자\n",
    "        succ_count += torch.sum(predicted == real_label).float().cpu().data\n",
    "        # 분모\n",
    "        total += real_label.size(0)\n",
    "    print(\"Test Data Accuracy: {}%\".format(100*(succ_count/total).numpy()))\n",
    "    if (succ_count/total).numpy() > 0.98:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "moderate-puppy",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seventh-gather",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CAM():\n",
    "    def __init__(self,model):\n",
    "        self.gradient = []\n",
    "        self.h = model.module.layer[-1].register_backward_hook(self.save_gradient)\n",
    "        \n",
    "    def save_gradient(self,*args):\n",
    "        grad_input = args[1]\n",
    "        grad_output= args[2]\n",
    "        self.gradient.append(grad_output[0])\n",
    "      \n",
    "    def get_gradient(self,idx):\n",
    "        return self.gradient[idx]\n",
    "    \n",
    "    def remove_hook(self):\n",
    "        self.h.remove()\n",
    "            \n",
    "    def normalize_cam(self,x):\n",
    "        x = 2*(x-torch.min(x))/(torch.max(x)-torch.min(x)+1e-8)-1\n",
    "        x[x<torch.max(x)]=-1\n",
    "        return x\n",
    "    \n",
    "    def visualize(self,cam_img,img_var):\n",
    "        cam_img = resize(cam_img.cpu().data.numpy(),output_shape=(64,64))\n",
    "        x = img_var[0,:,:].cpu().data.numpy()\n",
    "\n",
    "        plt.subplot(1,3,1)\n",
    "        plt.imshow(cam_img)\n",
    "\n",
    "        plt.subplot(1,3,2)\n",
    "        plt.imshow(x,cmap=\"gray\")\n",
    "\n",
    "        plt.subplot(1,3,3)\n",
    "        plt.imshow(x+cam_img)\n",
    "        plt.show()\n",
    "\n",
    "    def deprocess_image(x):\n",
    "        ## 평균을 0으로, 표준편차를 0.1로 하도록 normalize한다.\n",
    "        x -= x.mean()\n",
    "        x /= (x.std() + 1e-5)\n",
    "        x *= 0.1\n",
    "\n",
    "        ## [0, 1]사이로 클리핑한다.\n",
    "        x += 0.5\n",
    "        x = np.clip(x, 0, 1)\n",
    "\n",
    "        ## 255를 곱해 RGB 값으로 바꾼다.\n",
    "        x *= 255\n",
    "        \n",
    "        ## [0, 255]사이로 클리핑한 후 정수로 바꾼다. \n",
    "        x = np.clip(x, 0, 255).astype('uint8')\n",
    "        return x\n",
    "\n",
    "    \n",
    "    def get_cam(self,idx):\n",
    "        grad = self.get_gradient(idx)\n",
    "        alpha = torch.sum(grad,dim=3,keepdim=True)\n",
    "        alpha = torch.sum(alpha,dim=2,keepdim=True)\n",
    "        \n",
    "        cam = alpha[idx]*grad[idx]\n",
    "        cam = torch.sum(cam,dim=0)\n",
    "        cam = self.normalize_cam(cam)\n",
    "        \n",
    "        self.remove_hook()\n",
    "        return cam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "taken-photography",
   "metadata": {},
   "outputs": [],
   "source": [
    "cam = CAM(model)\n",
    "\n",
    "for i,[image,label] in enumerate(test_dataloader):\n",
    "    x = Variable(image).cuda()\n",
    "    x = x.float()\n",
    "    y_= Variable(label).cuda()\n",
    "        \n",
    "    output = model.forward(x)    \n",
    "    \n",
    "    for j in range(19):\n",
    "        model.zero_grad()\n",
    "        lab = y_[j].cpu().data\n",
    "        output[j,lab].backward(retain_graph=True)\n",
    "\n",
    "        out = cam.get_cam(j)\n",
    "        cam.visualize(out,x[j])\n",
    "\n",
    "    break"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "adopted-james",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
