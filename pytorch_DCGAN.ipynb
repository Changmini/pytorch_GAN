{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "monthly-butter",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-511fc32743e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moptim\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn,optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "according-worry",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Preprocessing\n",
    "batch_size = 32\n",
    "batchSize = 64\n",
    "imageSize = 64\n",
    "\n",
    "transform = transforms.Compose([transforms.Resize(64), transforms.CenterCrop(64),\n",
    "                                transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5),(0.5, 0.5, 0.5))])\n",
    "train_data = datasets.ImageFolder('/content/drive/My Drive/AI/input/data/train', transform = transform)\n",
    "dataloader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "imgs, label = next(iter(dataloader))\n",
    "imgs = imgs.numpy().transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developed-drain",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "image_size = 64\n",
    "\n",
    "random_transforms = [transforms.ColorJitter(), transforms.RandomRotation(degrees=20)]\n",
    "transforms = transforms.Compose([transforms.Resize(64), transforms.CenterCrop(64),\n",
    "                                 transforms.RandomHorizontalFlip(p=0.5),\n",
    "                                 transforms.ToTensor(),\n",
    "                                 transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "train_data = datasets.ImageFolder('/content/drive/My Drive/AI/input/data/train', transform=transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_data, shuffle=True, batch_size=batch_size)\n",
    "imgs, label = next(iter(train_loader))\n",
    "imgs = imgs.numpy().transpose(0, 2, 3, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "numeric-superintendent",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(20):\n",
    "  print(label[i])\n",
    "  plt.imshow(imgs[i])\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cardiac-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "#weight\n",
    "def weight_init(m):\n",
    "  classname = m.__class__.__name__\n",
    "  if classname.find('Conv') != -1:\n",
    "    m.weight.data.normal_(0.0, 0.02)\n",
    "  elif classname.find('BatchNorm') != -1:\n",
    "    m.weight.data.normal_(1.0, 0.02)\n",
    "    m.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "analyzed-stewart",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generator\n",
    "class G(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(G, self).__init__()\n",
    "    self.main = nn.Sequential(nn.ConvTranspose2d(100, 512, 4, stride=1, padding=0, bias=False),\n",
    "                              nn.BatchNorm2d(512), nn.ReLU(True),\n",
    "                              nn.ConvTranspose2d(512, 256, 4, stride=2, padding=1, bias=False),\n",
    "                              nn.BatchNorm2d(256),\n",
    "                              nn.ReLU(True),\n",
    "                              nn.ConvTranspose2d(256, 128, 4, stride=2, padding=1, bias=False),\n",
    "                              nn.BatchNorm2d(128),\n",
    "                              nn.ReLU(True),\n",
    "                              nn.ConvTranspose2d(128, 64, 4, stride=2, padding=1, bias=False),\n",
    "                              nn.BatchNorm2d(64),\n",
    "                              nn.ReLU(True),\n",
    "                              nn.ConvTranspose2d(64, 3, 4, stride=2, padding=1, bias=False),\n",
    "                              nn.Tanh())\n",
    "    \n",
    "  def forward(self, input):\n",
    "    output = self.main(input)\n",
    "    return output\n",
    "  \n",
    "netG = G()\n",
    "netG.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stable-consolidation",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Discriminator(구분자)\n",
    "class D(nn.Module):\n",
    "  #네트워크 구조\n",
    "  def __init__(self):\n",
    "    super(D, self).__init__()\n",
    "    self.main = nn.Sequential(\n",
    "        nn.Conv2d(3, 64, 4, stride=2, padding=1, bias=False),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        nn.Conv2d(64,128,4,stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(128),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        nn.Conv2d(128, 256, 4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(256),\n",
    "        nn.LeakyReLU(negative_slope=0.2, inplace=True),\n",
    "        nn.Conv2d(256, 512, 4, stride=2, padding=1, bias=False),\n",
    "        nn.BatchNorm2d(512),\n",
    "        nn.Conv2d(512, 1, 4, stride=1, padding=0, bias=False),\n",
    "        nn.Sigmoid()\n",
    "    )\n",
    "  \n",
    "  \n",
    "  def forward(self, input):\n",
    "    output = self.main(input)\n",
    "    return output.view(-1)\n",
    "\n",
    "netD = D()\n",
    "netD.apply(weight_init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "possible-frederick",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, nz=128, channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        \n",
    "        self.nz = nz\n",
    "        self.channels = channels\n",
    "        \n",
    "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0):\n",
    "            block = [\n",
    "                nn.ConvTranspose2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False),\n",
    "                nn.BatchNorm2d(n_output),\n",
    "                nn.ReLU(inplace=True),\n",
    "            ]\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *convlayer(self.nz, 1024, 4, 1, 0), # Fully connected layer via convolution.\n",
    "            *convlayer(1024, 512, 4, 2, 1),\n",
    "            *convlayer(512, 256, 4, 2, 1),\n",
    "            *convlayer(256, 128, 4, 2, 1),\n",
    "            *convlayer(128, 64, 4, 2, 1),\n",
    "            nn.ConvTranspose2d(64, self.channels, 3, 1, 1),\n",
    "            nn.Tanh()\n",
    "        )\n",
    "\n",
    "\n",
    "    def forward(self, z):\n",
    "        z = z.view(-1, self.nz, 1, 1)\n",
    "        #print(z)\n",
    "        z\n",
    "        img = self.model(z)\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immediate-spiritual",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        \n",
    "        self.channels = channels\n",
    "\n",
    "        def convlayer(n_input, n_output, k_size=4, stride=2, padding=0, bn=False):\n",
    "            block = [nn.Conv2d(n_input, n_output, kernel_size=k_size, stride=stride, padding=padding, bias=False)]\n",
    "            if bn:\n",
    "                block.append(nn.BatchNorm2d(n_output))\n",
    "            block.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return block\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *convlayer(self.channels, 32, 4, 2, 1),\n",
    "            *convlayer(32, 64, 4, 2, 1),\n",
    "            *convlayer(64, 128, 4, 2, 1, bn=True),\n",
    "            *convlayer(128, 256, 4, 2, 1, bn=True),\n",
    "            nn.Conv2d(256, 1, 4, 1, 0, bias=False),  # FC with Conv.\n",
    "        )\n",
    "\n",
    "    def forward(self, imgs):\n",
    "        logits = self.model(imgs)\n",
    "        out = torch.sigmoid(logits)\n",
    "    \n",
    "        return out.view(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "changing-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "LR_G = 0.001\n",
    "LR_D = 0.0005\n",
    "\n",
    "beta1 = 0.5\n",
    "epochs = 1000\n",
    "\n",
    "real_label = 0.9\n",
    "fake_label = 0.1\n",
    "nz = 128\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stuck-robertson",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델 및 최적화 프로그램 초기화\n",
    "netG = Generator(nz).to(device)\n",
    "netD = Discriminator().to(device)\n",
    "\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "optimizerD = optim.Adam(netD.parameters(), lr=LR_D, betas=(beta1, 0.999))\n",
    "optimizerG = optim.Adam(netG.parameters(), lr=LR_G, betas=(beta1, 0.999))\n",
    "\n",
    "fixed_noise = torch.randn(25, nz, 1, 1, device=device)\n",
    "\n",
    "G_losses = []\n",
    "D_losses = []\n",
    "epoch_time = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "oriental-convention",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss (G_losses, D_losses, epoch):\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.title(\"Generator and Discriminator Loss - EPOCH \"+ str(epoch))\n",
    "    plt.plot(G_losses,label=\"G\")\n",
    "    plt.plot(D_losses,label=\"D\")\n",
    "    plt.xlabel(\"iterations\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "multiple-comfort",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_generated_img(n_images=5):\n",
    "    sample = []\n",
    "    for _ in range(n_images):\n",
    "        noise = torch.randn(1, nz, 1, 1, device=device)\n",
    "        gen_image = netG(noise).to(\"cpu\").clone().detach().squeeze(0)\n",
    "        gen_image = gen_image.numpy().transpose(1, 2, 0)\n",
    "        sample.append(gen_image)\n",
    "    \n",
    "    figure, axes = plt.subplots(1, len(sample), figsize = (64,64))\n",
    "    for index, axis in enumerate(axes):\n",
    "        axis.axis('off')\n",
    "        image_array = sample[index]\n",
    "        axis.imshow(image_array)\n",
    "        \n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "quarterly-inflation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "creative-zimbabwe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    start = time.time()\n",
    "    for ii, (real_images, train_labels) in tqdm(enumerate(train_loader), total=len(train_loader)):\n",
    "\n",
    "        # train with real\n",
    "        netD.zero_grad()\n",
    "        real_images = real_images.to(device)\n",
    "        batch_size = real_images.size(0)\n",
    "        labels = torch.full((batch_size, 1), real_label, device=device)\n",
    "\n",
    "        output = netD(real_images)\n",
    "        errD_real = criterion(output, labels)\n",
    "        errD_real.backward()\n",
    "\n",
    "        # train with fake\n",
    "        noise = torch.randn(batch_size, nz, 1, 1, device=device)\n",
    "        fake = netG(noise)\n",
    "        labels.fill_(fake_label)\n",
    "        output = netD(fake.detach())\n",
    "        errD_fake = criterion(output, labels)\n",
    "        errD_fake.backward()\n",
    "\n",
    "        errD = errD_real + errD_fake\n",
    "        optimizerD.step()\n",
    "\n",
    "        netG.zero_grad()\n",
    "        labels.fill_(real_label)  # fake labels are real for generator cost\n",
    "        output = netD(fake)\n",
    "        errG = criterion(output, labels)\n",
    "        errG.backward()\n",
    "        optimizerG.step()\n",
    "        \n",
    "        # Save Losses for plotting later\n",
    "        G_losses.append(errG.item())\n",
    "        D_losses.append(errD.item())\n",
    "    \n",
    "    if epoch % 100 == 0:\n",
    "        show_generated_img()\n",
    "        plot_loss (G_losses, D_losses, epoch)\n",
    "        G_losses = []\n",
    "        D_losses = []\n",
    "    \n",
    "    epoch_time.append(time.time()- start)\n",
    "    \n",
    "#             valid_image = netG(fixed_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-priority",
   "metadata": {},
   "outputs": [],
   "source": [
    "print (\">> average EPOCH duration = \", np.mean(epoch_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hollow-synthetic",
   "metadata": {},
   "outputs": [],
   "source": [
    " if not os.path.exists('../output_images'):\n",
    "    os.mkdir('../output_images')\n",
    "    \n",
    "im_batch_size = 50\n",
    "n_images=10000\n",
    "\n",
    "for i_batch in tqdm(range(0, n_images, im_batch_size)):\n",
    "    gen_z = torch.randn(im_batch_size, nz, 1, 1, device=device)\n",
    "    gen_images = netG(gen_z)\n",
    "    images = gen_images.to(\"cpu\").clone().detach()\n",
    "    images = images.numpy().transpose(0, 2, 3, 1)\n",
    "    for i_image in range(gen_images.size(0)):\n",
    "        save_image(gen_images[i_image, :, :, :], os.path.join('../output_images', f'image_{i_batch+i_image:05d}.png'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "regional-northwest",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
